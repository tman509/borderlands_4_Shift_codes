name: Import Old Database

on:
  workflow_dispatch:
    inputs:
      backup_current:
        description: "Backup current database before import?"
        required: false
        type: boolean
        default: true
      import_source:
        description: "Source of old database"
        required: true
        type: choice
        options:
          - "Upload as artifact"
          - "From previous workflow run"
        default: "From previous workflow run"

permissions:
  contents: read

jobs:
  import-database:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download current database (if exists)
        if: ${{ inputs.backup_current == true }}
        uses: dawidd6/action-download-artifact@v2
        with:
          workflow: run_simple.yml
          name: shift_codes-database
          path: ./current/
          if_no_artifact_found: ignore

      - name: Download old database from artifacts
        if: ${{ inputs.import_source == 'Upload as artifact' }}
        uses: dawidd6/action-download-artifact@v2
        with:
          name: old-database
          path: ./old/
          if_no_artifact_found: fail

      - name: Download old database from previous run
        if: ${{ inputs.import_source == 'From previous workflow run' }}
        uses: dawidd6/action-download-artifact@v2
        with:
          workflow: run.yml  # Original workflow name
          name: shift_codes-database
          path: ./old/
          if_no_artifact_found: ignore

      - name: List available files for debugging
        run: |
          echo "ðŸ” Available files:"
          echo "Current directory:"
          ls -la
          echo "Old directory:"
          ls -la ./old/ 2>/dev/null || echo "No ./old/ directory"
          echo "Current directory:"
          ls -la ./current/ 2>/dev/null || echo "No ./current/ directory"
          echo "All .db files:"
          find . -name "*.db" -type f 2>/dev/null || echo "No .db files found"

      - name: Backup current database
        if: ${{ inputs.backup_current == true }}
        run: |
          if [ -f ./current/shift_codes.db ]; then
            echo "ðŸ“¦ Backing up current database..."
            cp ./current/shift_codes.db ./shift_codes_backup_$(date +%Y%m%d_%H%M%S).db
            echo "âœ… Current database backed up"
          else
            echo "â„¹ï¸ No current database to backup"
          fi

      - name: Import old database
        run: |
          echo "ðŸ”„ Starting database import..."
          
          # Determine old database path
          if [ -f ./old/shift_codes.db ]; then
            OLD_DB="./old/shift_codes.db"
            echo "ðŸ“‚ Found old database: $OLD_DB"
          else
            echo "âŒ No old database found to import"
            echo "Available files:"
            find . -name "*.db" -type f 2>/dev/null || echo "No .db files found"
            exit 1
          fi
          
          # Check if we have a current database to merge with
          if [ -f ./current/shift_codes.db ]; then
            echo "ðŸ“¥ Merging with existing database"
            cp ./current/shift_codes.db ./shift_codes_existing.db
            NEW_DB="./shift_codes_existing.db"
          else
            echo "ðŸ“¥ Creating new database"
            NEW_DB="./shift_codes_new.db"
          fi
          
          echo "Old database: $OLD_DB"
          echo "New database: $NEW_DB"
          
          # Check old database
          echo "ðŸ” Checking old database..."
          python -c "
          import sqlite3
          import os
          
          if not os.path.exists('$OLD_DB'):
              print('âŒ Old database file not found')
              exit(1)
          
          try:
              conn = sqlite3.connect('$OLD_DB')
              cursor = conn.cursor()
              cursor.execute('SELECT COUNT(*) FROM codes')
              count = cursor.fetchone()[0]
              print(f'âœ… Old database has {count} codes')
              conn.close()
          except Exception as e:
              print(f'âŒ Error reading old database: {e}')
              exit(1)
          "
          
          # Run import with CI script (no interactive prompts)
          python import_database_ci.py "$OLD_DB" "$NEW_DB"
          
          # Move result to final location
          if [ -f "$NEW_DB" ]; then
            mv "$NEW_DB" ./shift_codes.db
            echo "âœ… Database import completed"
          else
            echo "âŒ Import failed - no output database created"
            exit 1
          fi

      - name: Verify import results
        run: |
          echo "ðŸ” Verifying import results..."
          
          python -c "
          import sqlite3
          
          conn = sqlite3.connect('./shift_codes.db')
          cursor = conn.cursor()
          
          # Get total count
          cursor.execute('SELECT COUNT(*) FROM codes')
          total = cursor.fetchone()[0]
          
          # Get active count
          cursor.execute('SELECT COUNT(*) FROM codes WHERE is_active = 1')
          active = cursor.fetchone()[0]
          
          # Get recent codes
          cursor.execute('SELECT code, reward_type, date_found_utc FROM codes ORDER BY date_found_utc DESC LIMIT 5')
          recent = cursor.fetchall()
          
          print(f'ðŸ“Š Database Statistics:')
          print(f'  Total codes: {total}')
          print(f'  Active codes: {active}')
          print(f'  Recent codes:')
          for code, reward, date in recent:
              print(f'    - {code} ({reward or \"Unknown\"}) - {date}')
          
          conn.close()
          "

      - name: Upload merged database
        uses: actions/upload-artifact@v4
        with:
          name: shift_codes-database
          path: |
            shift_codes.db
            shift_codes_backup_*.db
          retention-days: 30

      - name: Send notification
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          if [ -n "$DISCORD_WEBHOOK_URL" ]; then
            echo "ðŸ“¢ Sending import completion notification..."
            
            # Get database stats
            TOTAL=$(python -c "import sqlite3; conn = sqlite3.connect('./shift_codes.db'); cursor = conn.cursor(); cursor.execute('SELECT COUNT(*) FROM codes'); print(cursor.fetchone()[0]); conn.close()")
            
            payload='{"content":"âœ… **Database Import Completed**\nOld SHiFT codes have been successfully imported!\n\nðŸ“Š **Total codes in database:** '"$TOTAL"'\n\nðŸ’¡ **Next run will only notify about NEW codes**\n**Time:** '"$(date -u '+%Y-%m-%d %H:%M')"' UTC"}'
            curl -sS -H "Content-Type: application/json" -X POST -d "$payload" "$DISCORD_WEBHOOK_URL"
            echo "âœ… Notification sent"
          else
            echo "â„¹ï¸ No Discord webhook configured for notifications"
          fi

      - name: Summary
        run: |
          echo "## ðŸŽ‰ Database Import Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Import completed successfully!**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Database Statistics" >> $GITHUB_STEP_SUMMARY
          
          TOTAL=$(python -c "import sqlite3; conn = sqlite3.connect('./shift_codes.db'); cursor = conn.cursor(); cursor.execute('SELECT COUNT(*) FROM codes'); print(cursor.fetchone()[0]); conn.close()")
          echo "- **Total codes:** $TOTAL" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸš€ Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "1. Your old codes are now imported" >> $GITHUB_STEP_SUMMARY
          echo "2. Future bot runs will only notify about NEW codes" >> $GITHUB_STEP_SUMMARY
          echo "3. No more notification spam!" >> $GITHUB_STEP_SUMMARY